{"cells":[{"cell_type":"code","execution_count":23,"id":"bb1115eb-e872-4cf7-87d9-da4adf9c2d21","metadata":{"id":"bb1115eb-e872-4cf7-87d9-da4adf9c2d21"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"7f44ba4e","metadata":{"id":"7f44ba4e"},"source":["## Dataset MNIST\n","\n","El dataset **MNIST** consiste en imágenes de números manuscritos entre 0 y 9. Las imágenes tienen dimensiones de 28x28 pixeles y cada pixel está representado por un valor de intensidad en escala de grises. El conjunto de entrenamiento consiste en 60000 dígitos y el conjunto de prueba de 10000.\n","\n","### Implemente una CNN para obtener un desempeño de al menos 99% de accuracy en el conjunto de prueba"]},{"cell_type":"code","execution_count":24,"id":"a13727d6","metadata":{},"outputs":[],"source":["#Importamos las librerias y la base de datos MNIST\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist"]},{"cell_type":"code","execution_count":25,"id":"e8eff1c5","metadata":{},"outputs":[],"source":["# Cargar el dataset MNIST\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","#train_images es un array de 60.000 imagenes de 28x28 pixeles\n","#train_labels es un array de 60.000 etiquetas de 0 a 9\n","#test_images es un array de 10.000 imagenes de 28x28 pixeles\n","#test_labels es un array de 10.000 etiquetas de 0 a 9\n"]},{"cell_type":"code","execution_count":26,"id":"fab327fe","metadata":{},"outputs":[],"source":["# Preprocesamos los datos\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","#train_images es un array de 60.000 imagenes de 28x28 pixeles y 1 canal\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","#test_images es un array de 10.000 imagenes de 28x28 pixeles y 1 canal\n","\n","# Normalizamos los valores de los pixeles de las imagenes\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","#Normalizamos las imagenes para que los valores esten entre 0 y 1"]},{"cell_type":"code","execution_count":27,"id":"62bbc165","metadata":{},"outputs":[],"source":["# Definimos la red neuronal convolucional\n","model = models.Sequential([ #28x28 es la entrada de la red\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), #32 filtros de 3x3, imput_shape es el tamaño de la imagen\n","    layers.MaxPooling2D((2, 2)), #MaxPooling lo que hace es muestrear, apsa los maximos valores de la imagen, en este caso de 2x2 de ese cuadrado elijo maximo el q pasa\n","    layers.Conv2D(64, (3, 3), activation='relu'), #64 filtros de 3x3, relu es la funcion de activacion, recibe un valor y devuelve el mismo si es positivo o 0 si es negativo\n","    layers.MaxPooling2D((2, 2)), #aumento la capa al doble, aumento el numero de filtros\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.Flatten(),#aplanamos la imagen, la convertimos en un vector\n","    layers.Dense(64, activation='relu'), #64 neuronas\n","    layers.Dense(10, activation='softmax') #10 porque son 10 clases\n","])"]},{"cell_type":"code","execution_count":28,"id":"8b48fecf","metadata":{},"outputs":[],"source":["# Compilamos el modelo\n","model.compile(optimizer='adam', #algortimo elegido, podria ser sgd o rmsprop\n","              loss='sparse_categorical_crossentropy', #funcion de perdida, es la funcion que se minimiza. poruwe teniamos salidas diferenctes salidas categoricas\n","              metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":29,"id":"f2d28c15","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","938/938 [==============================] - 30s 31ms/step - loss: 0.1736 - accuracy: 0.9474\n","Epoch 2/15\n","938/938 [==============================] - 32s 34ms/step - loss: 0.0500 - accuracy: 0.9845\n","Epoch 3/15\n","938/938 [==============================] - 33s 36ms/step - loss: 0.0359 - accuracy: 0.9884\n","Epoch 4/15\n","938/938 [==============================] - 34s 36ms/step - loss: 0.0277 - accuracy: 0.9915\n","Epoch 5/15\n","938/938 [==============================] - 36s 39ms/step - loss: 0.0209 - accuracy: 0.9930\n","Epoch 6/15\n","938/938 [==============================] - 34s 36ms/step - loss: 0.0182 - accuracy: 0.9944\n","Epoch 7/15\n","938/938 [==============================] - 37s 39ms/step - loss: 0.0143 - accuracy: 0.9957\n","Epoch 8/15\n","938/938 [==============================] - 36s 38ms/step - loss: 0.0120 - accuracy: 0.9962\n","Epoch 9/15\n","938/938 [==============================] - 34s 37ms/step - loss: 0.0102 - accuracy: 0.9964\n","Epoch 10/15\n","938/938 [==============================] - 33s 36ms/step - loss: 0.0094 - accuracy: 0.9969\n","Epoch 11/15\n","938/938 [==============================] - 31s 33ms/step - loss: 0.0086 - accuracy: 0.9973\n","Epoch 12/15\n","938/938 [==============================] - 32s 34ms/step - loss: 0.0076 - accuracy: 0.9977\n","Epoch 13/15\n","938/938 [==============================] - 32s 34ms/step - loss: 0.0070 - accuracy: 0.9977\n","Epoch 14/15\n","938/938 [==============================] - 32s 34ms/step - loss: 0.0057 - accuracy: 0.9980\n","Epoch 15/15\n","938/938 [==============================] - 28s 30ms/step - loss: 0.0065 - accuracy: 0.9978\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x11329884890>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenamos el modelo\n","model.fit(train_images, train_labels, epochs=15, batch_size=64)\n","#entreno con 15 epocas y un batch de 64 imagenes, aumenté la cantidad de épocas para que me de mejor\n","#si vuelvo a entrenar me da mejor, porque se entrena con lo que ya aprendio"]},{"cell_type":"code","execution_count":30,"id":"1e477940","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9922\n","Accuracy en el conjunto de prueba: 99.22%\n"]}],"source":["# Evaluamos el modelo en el conjunto de prueba\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'Accuracy en el conjunto de prueba: {test_acc*100:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}
